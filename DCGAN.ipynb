{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "GAN-keras-mnist-DCGAN.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1df5f1af2d7e4c938febaacb42c9f332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2412edff03d443619f0da089f5c49c80",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eaaee9f16e3445d8b52ce2bf305b617b",
              "IPY_MODEL_f15fa7f1164f4e79aab27e96a1b62f4b"
            ]
          }
        },
        "2412edff03d443619f0da089f5c49c80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eaaee9f16e3445d8b52ce2bf305b617b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4b0cf78d871b419ea1b13b09367bcb1c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 200,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 200,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_574bd971cf0d495bb268c8aa63dbcccb"
          }
        },
        "f15fa7f1164f4e79aab27e96a1b62f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b40fc0da6a194a31ace058c49edb8e48",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 200/200 [09:11&lt;00:00,  2.76s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60f8e285cb284d47bdc7b9096bcd4095"
          }
        },
        "4b0cf78d871b419ea1b13b09367bcb1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "574bd971cf0d495bb268c8aa63dbcccb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b40fc0da6a194a31ace058c49edb8e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60f8e285cb284d47bdc7b9096bcd4095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "GkJ1XC6aONsH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81f47928-58d6-4b3d-860f-b25829dec96a"
      },
      "source": [
        "#Importing required libraries.\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, Activation, Flatten, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose, UpSampling2D, Convolution2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tqdm import tqdm_notebook\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCefjGgXUNDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "7P2ngsivONsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing : This step is crucial for this type of GAN , because here the images fed to discriminator must have a size with channels included.\n",
        "#Therefore we reshape the b&w images with 1 channel to (28,28,1).\n",
        "\n",
        "X_train = X_train.reshape(60000, 28, 28, 1)\n",
        "X_test = X_test.reshape(10000, 28, 28, 1)\n",
        "X_train = X_train.astype('float32')/255\n",
        "X_test = X_test.astype('float32')/255"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS-JOt_hQCv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using images of 0 only so to make datset smaller and training time faster.\n",
        "\n",
        "X_train= X_train[Y_train==0]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "dt6_vYsxONs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the dimensions of the noise\n",
        "z_dim = 100"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q9N4PCsONtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "nch = 200\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "gKdCSnlTONtV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "74279120-65bd-4cb0-a3d1-012ce549564c"
      },
      "source": [
        "# Here we define the architecture of GAN which consists of both \"generator\" and \"discriminator\". \n",
        "#We define architecture of Generator which is fully-convolutional network. It accepts noise as input and generates am image out of it.\n",
        "#Generator learns when gradients are backpropagated through the network just after discriminator clasifies any image real or fake.\n",
        "#A special type of convolutional layer is being used here which increases the dimension of input image/array by using transpose convolution notion.\n",
        "#Because network discriminates between real and generated image , therefore this uses \"binary_crossentropy\" as loss.\n",
        "#First encoding is fed to generator which generates an image from it and then subsequently the generated image is fed into discriminator for it to classify\n",
        "# image as real or fake. \n",
        "#Thus in the whole architecture , they both fight against each other. And thus make each other learn more everytime.\n",
        "adam = Adam(lr=0.0002, beta_1=0.5)\n",
        "\n",
        "g = Sequential()\n",
        "g.add(Dense(7*7*112, input_dim=z_dim))\n",
        "g.add(Reshape((7, 7, 112)))\n",
        "g.add(BatchNormalization())\n",
        "g.add(Activation(LeakyReLU(alpha=0.2)))\n",
        "g.add(Conv2DTranspose(56, 5, strides=2, padding='same'))\n",
        "g.add(BatchNormalization())\n",
        "g.add(Activation(LeakyReLU(alpha=0.2)))\n",
        "g.add(Conv2DTranspose(1, 5, strides=2, padding='same', activation='sigmoid'))\n",
        "g.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "g.summary()\n",
        "\n",
        "d = Sequential()\n",
        "d.add(Conv2D(56, 5, strides=2, padding='same', input_shape=(28, 28, 1), activation=LeakyReLU(alpha=0.2)))\n",
        "d.add(Conv2D(112, 5, strides=2, padding='same'))\n",
        "g.add(BatchNormalization())\n",
        "g.add(Activation(LeakyReLU(alpha=0.2)))\n",
        "d.add(Conv2D(224, 5, strides=2, padding='same'))\n",
        "g.add(Activation(LeakyReLU(alpha=0.2)))\n",
        "d.add(Flatten())\n",
        "d.add(Dense(112, activation=LeakyReLU(alpha=0.2)))\n",
        "d.add(Dense(1, activation='sigmoid'))\n",
        "d.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "d.summary()\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 5488)              554288    \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 7, 7, 112)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 7, 7, 112)         448       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 7, 7, 112)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 14, 14, 56)        156856    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 14, 14, 56)        224       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 14, 14, 56)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         1401      \n",
            "=================================================================\n",
            "Total params: 713,217\n",
            "Trainable params: 712,881\n",
            "Non-trainable params: 336\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 14, 14, 56)        1456      \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 7, 7, 112)         156912    \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 4, 4, 224)         627424    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3584)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 112)               401520    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 113       \n",
            "=================================================================\n",
            "Total params: 1,187,425\n",
            "Trainable params: 1,187,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocOZyaSDWQ3H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "946ede24-35c3-4d71-f021-f23e1142402c"
      },
      "source": [
        "#We first make discriminator non-trainable so it just classify images simply and do not learn anything from the data fed to it.\n",
        "#And we set the complete loss-fnunction and optimizer. Advanced architectures uses various kind of loss so to make it more \n",
        "# efficient.\n",
        "\n",
        "d.trainable = False\n",
        "inputs = Input(shape=(z_dim, ))\n",
        "hidden = g(inputs)\n",
        "output = d(hidden)\n",
        "gan = Model(inputs, output)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "gan.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 28, 28, 1)         713221    \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 1)                 1187425   \n",
            "=================================================================\n",
            "Total params: 1,900,646\n",
            "Trainable params: 712,883\n",
            "Non-trainable params: 1,187,763\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "UpQeN9CQONtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This is train function which trains the whole architecture in one. \n",
        "#First an random noise is generated and is fed to generator \"g\" which generates some noisy image from it as the generator is not yet trained.\n",
        "#The generated noisy image is then concatenated with real images and all of them are fed into discriminator. Discriminator is tricked to believe that they\n",
        "#real images as we give target as \"0\". It then learns somehting about the real images. \n",
        "#Then comes the generator's training. We simply generate some more random noise, set target as \"1\" so to make the \"GAN\" believe that they are real images.\n",
        "#Just then we make discriminator non-trainable and feed this data into whole \"GAN\" architecture. Thus the generator learns when the loop completes and \n",
        "# the gradients flow back assuming that all of the images given were real images.\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "rGhRqJXZONtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up a vector (dict) to store the losses\n",
        "samples = []\n",
        "\n",
        "def train(epochs=1, plt_frq=1, BATCH_SIZE=128):\n",
        "    batchCount = int(X_train.shape[0] / BATCH_SIZE)\n",
        "    print('Epochs:', epochs)\n",
        "    print('Batch size:', BATCH_SIZE)\n",
        "    print('Batches per epoch:', batchCount)\n",
        "    \n",
        "    for e in tqdm_notebook(range(1, epochs+1)):\n",
        "        if e == 1 or e%plt_frq == 0:\n",
        "            print('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "        for _ in range(batchCount):  # tqdm_notebook(range(batchCount), leave=False):\n",
        "            # Create a batch by drawing random index numbers from the training set\n",
        "            image_batch = X_train[np.random.randint(0, X_train.shape[0], size=BATCH_SIZE)]\n",
        "            image_batch = image_batch.reshape(image_batch.shape[0], image_batch.shape[1], image_batch.shape[2], 1)\n",
        "            # Create noise vectors for the generator\n",
        "            noise = np.random.normal(0, 1, size=(BATCH_SIZE, z_dim))\n",
        "            \n",
        "            # Generate the images from the noise\n",
        "            generated_images = g.predict(noise)\n",
        "            samples.append(generated_images)\n",
        "            X = np.concatenate((image_batch, generated_images))\n",
        "            # Create labels\n",
        "            y = np.zeros(2*BATCH_SIZE)\n",
        "            y[:BATCH_SIZE] = 0.9  # One-sided label smoothing\n",
        "\n",
        "            # Train discriminator on generated images\n",
        "            d.trainable = True\n",
        "            d_loss = d.train_on_batch(X, y)\n",
        "\n",
        "            # Train generator\n",
        "            noise = np.random.normal(0, 1, size=(BATCH_SIZE, z_dim))\n",
        "            y2 = np.ones(BATCH_SIZE)\n",
        "            d.trainable = False\n",
        "            g_loss = gan.train_on_batch(noise, y2)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "7xDXH3RbONty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355,
          "referenced_widgets": [
            "1df5f1af2d7e4c938febaacb42c9f332",
            "2412edff03d443619f0da089f5c49c80",
            "eaaee9f16e3445d8b52ce2bf305b617b",
            "f15fa7f1164f4e79aab27e96a1b62f4b",
            "4b0cf78d871b419ea1b13b09367bcb1c",
            "574bd971cf0d495bb268c8aa63dbcccb",
            "b40fc0da6a194a31ace058c49edb8e48",
            "60f8e285cb284d47bdc7b9096bcd4095"
          ]
        },
        "outputId": "b495c787-5534-4d83-ea26-60ed0055ca9d"
      },
      "source": [
        "#Training 50 epochs.\n",
        "train(epochs=200, plt_frq=20, BATCH_SIZE=128)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epochs: 200\n",
            "Batch size: 128\n",
            "Batches per epoch: 46\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1df5f1af2d7e4c938febaacb42c9f332",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 1 ---------------\n",
            "--------------- Epoch 20 ---------------\n",
            "--------------- Epoch 40 ---------------\n",
            "--------------- Epoch 60 ---------------\n",
            "--------------- Epoch 80 ---------------\n",
            "--------------- Epoch 100 ---------------\n",
            "--------------- Epoch 120 ---------------\n",
            "--------------- Epoch 140 ---------------\n",
            "--------------- Epoch 160 ---------------\n",
            "--------------- Epoch 180 ---------------\n",
            "--------------- Epoch 200 ---------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azU6du2TONt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FzCMcJtONuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2n-u34yTRzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generating random noise and then feeding it to generator which generates some image/array from it ."
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCGq6HXsTWAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  n_ex=10\n",
        "  dim=(1, 10)\n",
        "  noise = np.random.normal(0, 1, size=(n_ex, z_dim))\n",
        "  generated_images = g.predict(noise)\n",
        "  generated_images = generated_images.reshape(generated_images.shape[0], 28, 28)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1PrHg6KTY6Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "b618e743-99fe-4b42-c372-2fbbf49f983d"
      },
      "source": [
        "plt.imshow(generated_images[0, :, :], interpolation='nearest', cmap='gray_r')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f37ba574828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M21hR6ptUGMk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "c8c238e9-a5aa-4a60-9806-f1781245209a"
      },
      "source": [
        "plt.imshow(generated_images[1, :, :], interpolation='nearest', cmap='gray_r')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f37ba62c7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQlUlEQVR4nO3da4wVZZ7H8d9fULmpEc8GUUg7M9GgMS6OrcF4CTo4ijHeXsiIUcbgMi+8MGQS1ssLSXxjNosTMWYM42Vwo3jJDIgRd3XMRB2DHVpErrq6CrGRy3RQRgiiwH9fdDHp0a7naU6d6ip4vp+k06fr39X17+r+dZ2u51Q95u4CcPg7ouoGAAwMwg4kgrADiSDsQCIIO5CIwQO5sUaj4W1tbQO5SSApGzduVHd3t/VVKxR2M7tC0sOSBkl63N0fDH1+W1ubOjo6imwSByk2tGrW5+8Faiz0M50wYUJuremn8WY2SNKjkiZLOkPSjWZ2RrNfD0C5ivzPfp6kT9z9U3f/VtJzkq5pTVsAWq1I2E+W9Hmvj7uyZf/EzGaYWaeZdXZ3dxfYHIAiSj8b7+7z3b3d3dsbjUbZmwOQo0jYN0ka2+vjMdkyADVUJOzLJZ1qZj8ys6Mk/ULSkta0BaDVmh56c/e9ZnaHpP9Rz9Dbk+6+tmWdoSUO5aG1/fv3B+tHHJHma8Ka/ZkWGmd396WSlhb5GgAGRpp/GoEEEXYgEYQdSARhBxJB2IFEEHYgEQN6PTtwMGLj6Fy+e3A4sgOJIOxAIgg7kAjCDiSCsAOJIOxAIhh6wyGLobWDw5EdSARhBxJB2IFEEHYgEYQdSARhBxJB2IFEMM6OQvbt2xesz549O7c2fPjw4LoXX3xxUz0dMGnSpELrH244sgOJIOxAIgg7kAjCDiSCsAOJIOxAIgg7kIjDZpyd2wqXY/Xq1cH6ww8/HKy/++67ubWhQ4cG1120aFGwPmTIkGB9xIgRubUJEyYE1y2qjr+PhcJuZhskfS1pn6S97t7eiqYAtF4rjuyXuHt3C74OgBLxPzuQiKJhd0mvmdl7Zjajr08wsxlm1mlmnd3dPAEAqlI07Be6+08lTZZ0u5n94MoFd5/v7u3u3t5oNApuDkCzCoXd3Tdl77dJWiTpvFY0BaD1mg67mQ03s2MOPJb0c0lrWtUYgNYqcjZ+lKRF2XjhYEnPuvt/t6SrJhQdt6zjuGh/hXqLfV+zZs0K1l9++eVgffv27cH6sGHDcmtTpkwJrtvR0RGsr1ixIlhfunRpbu38888Prrt///5gvc6/D3maDru7fyrpX1vYC4ASMfQGJIKwA4kg7EAiCDuQCMIOJOKwucS1qCqHUvbu3Vto/Q8++CC39tBDDwXX/eyzz4L1L774oqmeDgjdLnrVqlXBdceNGxesh75vSXr77bdza2UPtcbWD22/rN9FjuxAIgg7kAjCDiSCsAOJIOxAIgg7kAjCDiSCcfYaGDw4/GPYtWtXsP7CCy/k1jo7O4PrdnV1BevfffddsB6zbdu23Nr69euD61533XXB+saNG4P1999/P7d25513BtedO3dusH7UUUcF6zFVvK6DIzuQCMIOJIKwA4kg7EAiCDuQCMIOJIKwA4lgnP0QsGzZsmB969atubVNmzYF1/3222+b6umA2HjzSSedlFt75plnguuec845wfrUqVOD9VNOOSW3FppKWopPBx271XQdcWQHEkHYgUQQdiARhB1IBGEHEkHYgUQQdiARjLMPgNi1y7H7p8emVQ5dM150HP2YY44J1mfOnBmsX3311bm18ePHB9eN3ds9dh+A0LZffPHF4LqvvPJKsD558uRgvY6iR3Yze9LMtpnZml7LRprZ62b2cfb++HLbBFBUf57G/0HSFd9bdrekN9z9VElvZB8DqLFo2N39LUnbv7f4GkkLsscLJF3b4r4AtFizJ+hGufvm7PEWSaPyPtHMZphZp5l1dnd3N7k5AEUVPhvvPWdRcs+kuPt8d2939/ZGo1F0cwCa1GzYt5rZaEnK3uefDgZQC82GfYmkadnjaZJeak07AMoSHWc3s4WSJkpqmFmXpPslPSjpBTObLmmjpBvKbLI/yp5vu0yvvvpqsL5jx45gPXRtdex689D86ZL03HPPBeuXXHJJsB7a77Gf2c6dO4P1WO9TpkzJrcXG2R9//PFg/fLLLw/Wjziifq9Xi4bd3W/MKf2sxb0AKFH9/vwAKAVhBxJB2IFEEHYgEYQdSASXuLZAbFhv8eLFwfry5cuD9djwWVtbW24tdonr/fffH6xfeumlwXrsew9N+Txo0KDgukOHDg3WY9rb23Nrsb47OjqC9S+//DJYP+GEE4L1KnBkBxJB2IFEEHYgEYQdSARhBxJB2IFEEHYgEYfNOHvZl7CGLlmMTd87b968YH3NmjXB+umnnx6sP/LII7m1s846K7huTOwy1Fg9NpZeRGzb9913X25tz549wXVDr12QpBEjRgTrdcSRHUgEYQcSQdiBRBB2IBGEHUgEYQcSQdiBRBw24+xlC43pzpkzJ7hu7Hr14447Lli//vrrg/UiY+mxseoyFX1tRKz3ZcuW5dZiU1HH7gOwe/fuYH3IkCHBehX7nSM7kAjCDiSCsAOJIOxAIgg7kAjCDiSCsAOJqNU4e52nXQ7dJ/y1114Lrjt4cHg333rrrcH6zJkzg/Uqx8qL2LdvX7AeuxY+tn7oHgSx69lPO+20YP3DDz8M1s8999xgvczr/PNEj+xm9qSZbTOzNb2WzTGzTWa2Mnu7stw2ARTVn6fxf5B0RR/Lf+vu47O3pa1tC0CrRcPu7m9J2j4AvQAoUZETdHeY2arsaf7xeZ9kZjPMrNPMOru7uwtsDkARzYb9d5J+Imm8pM2S5uZ9orvPd/d2d29vNBpNbg5AUU2F3d23uvs+d98v6feSzmttWwBaramwm9noXh9eJyl8L2QAlYuOs5vZQkkTJTXMrEvS/ZImmtl4SS5pg6RfldhjLYTGVbu6uoLrHn300cH6VVddFazHxmT37t0brJepyGsjYt9X7HUVb775ZrAeuiY9NAYvxe8RcOaZZwbrVYyjx0TD7u439rH4iRJ6AVAiXi4LJIKwA4kg7EAiCDuQCMIOJKJWl7jW2a5du3JrsSmbx4wZE6zv2LEjWC9yCWvZt2uOff1QPfa1Fy9eHKzPnZv7wk1J0oYNG3JrsaG32M+MKZsB1BZhBxJB2IFEEHYgEYQdSARhBxJB2IFE1GqcvcpbRceMHTs2txa7hPWrr74K1h999NFg/bLLLgvWy9xvRb/2zp07c2sLFy4MrhuaclmSPv/882B95MiRubXp06cH1501a1awHlPktRFl3RqcIzuQCMIOJIKwA4kg7EAiCDuQCMIOJIKwA4mo1Th7nZ144om5taLjoscee2yw/s033wTrQ4cOza0V7S10Hb8kPfXUU8H6008/nVuL3Qcgdp1/bCrsW265Jbd21113BdeNKXOa7LJeN8GRHUgEYQcSQdiBRBB2IBGEHUgEYQcSQdiBRNRqnL3oPcqLiH3t0Fh4W1tbcN3u7u5gPTaO/thjjwXroSmblyxZElx39+7dwXpsLDt0b3ZJ2rNnT24tNs4+bNiwYH3SpEnB+j333JNbi/28yxxHr0r0yG5mY83sL2a2zszWmtnMbPlIM3vdzD7O3h9ffrsAmtWfp/F7Jf3G3c+QNEHS7WZ2hqS7Jb3h7qdKeiP7GEBNRcPu7pvdfUX2+GtJ6yWdLOkaSQuyT1sg6dqymgRQ3EGdoDOzUySdLalD0ih335yVtkgalbPODDPrNLPO2P+uAMrT77Cb2QhJf5T0a3f/e++a95zN6POMhrvPd/d2d29vNBqFmgXQvH6F3cyOVE/Qn3H3P2WLt5rZ6Kw+WtK2cloE0ArRoTfrGaN4QtJ6d3+oV2mJpGmSHszev1S0mSpvJV1kqOW2224L1ufNmxesr127Nlhft25dsL5ly5bcWmx4K1aP/UxiQ3ODBg3KrV1wwQXBdWfPnh2sX3TRRcF6kemii4rt19iU0WXozzj7BZJulrTazFZmy+5VT8hfMLPpkjZKuqGcFgG0QjTs7v5XSXl/In/W2nYAlIWXywKJIOxAIgg7kAjCDiSCsAOJqNUlroeqm266KVhfunRpsP7OO+8E66FLWCVp9OjRubXQGLwUH++NbTs2zh6aNvmBBx4Irnv22WcH6zFVXqZax+nHObIDiSDsQCIIO5AIwg4kgrADiSDsQCIIO5CIWo2zV3kr6TKFpi2WpGeffTZYf/7554P1jz76KLc2ZMiQ4LpjxowJ1seNGxesT506NVifOHFibi02xn8o3865zN/VZvcLR3YgEYQdSARhBxJB2IFEEHYgEYQdSARhBxJRq3H2Q3UcPSZ2D/Gbb745WJ82bVpp244p+jMJjQkX7a3ItmPqPIdBs71xZAcSQdiBRBB2IBGEHUgEYQcSQdiBRBB2IBH9mZ99rKSnJY2S5JLmu/vDZjZH0r9J+lv2qfe6e/gG6Yk68sgjC61f9nh0SJnXlJc9R/mh+rqNsvruz4tq9kr6jbuvMLNjJL1nZq9ntd+6+3+W0hmAlurP/OybJW3OHn9tZuslnVx2YwBa66CeR5nZKZLOltSRLbrDzFaZ2ZNmdnzOOjPMrNPMOru7uws1C6B5/Q67mY2Q9EdJv3b3v0v6naSfSBqvniP/3L7Wc/f57t7u7u2NRqMFLQNoRr/CbmZHqifoz7j7nyTJ3be6+z533y/p95LOK69NAEVFw249pwafkLTe3R/qtbz31KHXSVrT+vYAtEp/zsZfIOlmSavNbGW27F5JN5rZePUMx22Q9KtSOgTQEv05G/9XSX0N/DGmDhxCeAUdkAjCDiSCsAOJIOxAIgg7kAjCDiSCsAOJIOxAIgg7kAjCDiSCsAOJIOxAIgg7kAjCDiTCyrxV8A82ZvY3SRt7LWpIquuN6eraW137kuitWa3src3d/6WvwoCG/QcbN+t09/bKGgioa2917Uuit2YNVG88jQcSQdiBRFQd9vkVbz+krr3VtS+J3po1IL1V+j87gIFT9ZEdwAAh7EAiKgm7mV1hZh+Z2SdmdncVPeQxsw1mttrMVppZZ8W9PGlm28xsTa9lI83sdTP7OHvf5xx7FfU2x8w2ZftupZldWVFvY83sL2a2zszWmtnMbHml+y7Q14DstwH/n93MBkn6X0mXSeqStFzSje6+bkAbyWFmGyS1u3vlL8Aws4sl7ZT0tLufmS37D0nb3f3B7A/l8e7+7zXpbY6knVVP453NVjS69zTjkq6V9EtVuO8Cfd2gAdhvVRzZz5P0ibt/6u7fSnpO0jUV9FF77v6WpO3fW3yNpAXZ4wXq+WUZcDm91YK7b3b3FdnjryUdmGa80n0X6GtAVBH2kyV93uvjLtVrvneX9JqZvWdmM6pupg+j3H1z9niLpFFVNtOH6DTeA+l704zXZt81M/15UZyg+6EL3f2nkiZLuj17ulpL3vM/WJ3GTvs1jfdA6WOa8X+oct81O/15UVWEfZOksb0+HpMtqwV335S93yZpkeo3FfXWAzPoZu+3VdzPP9RpGu++phlXDfZdldOfVxH25ZJONbMfmdlRkn4haUkFffyAmQ3PTpzIzIZL+rnqNxX1EknTssfTJL1UYS//pC7TeOdNM66K913l05+7+4C/SbpSPWfk/0/SfVX0kNPXjyV9kL2trbo3SQvV87TuO/Wc25gu6QRJb0j6WNKfJY2sUW//JWm1pFXqCdboinq7UD1P0VdJWpm9XVn1vgv0NSD7jZfLAongBB2QCMIOJIKwA4kg7EAiCDuQCMIOJIKwA4n4fz0DPu5+nWLdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciMyrVzmUJWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    }
  ]
}